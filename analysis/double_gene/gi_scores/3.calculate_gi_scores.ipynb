{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the model fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify random seed and epochs ----------------------------------------\n",
    "random_seed=12\n",
    "num_epochs=100\n",
    "use_pred_single = False # True if using predicted single perturbation, False if using true single perturbation\n",
    "filter_zeros = False\n",
    "\n",
    "# Specify the model type and model name ----------------------------------------\n",
    "model_type='morph' # Gears or morph or Control (for baseline) or Truth\n",
    "if model_type == 'morph':\n",
    "    representation_type='DepMap_GeneEffect'\n",
    "    model_name = 'best_model'\n",
    "    recon_loss = 'mmd'\n",
    "    null_label = 'zeros'\n",
    "    mxAlpha = 2.0\n",
    "    tolerance_epochs = 20\n",
    "elif model_type == 'Gears':\n",
    "    model_name='model.pt'\n",
    "elif model_type == 'Control':\n",
    "    model_name=None\n",
    "elif model_type == 'Truth':\n",
    "    model_name=None\n",
    "\n",
    "# Specify the number of genes to use -------------------------------------------\n",
    "num_gene = 2500\n",
    "n_subsamples = 1000 # whether to set n_subsamples in TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'norman_k562_hvg'\n",
    "dataset = dataset_name.replace('_hvg', '')\n",
    "use_hvg = 'True' if 'hvg' in dataset_name else 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = f'/home/che/perturb-project/git/gene_ptb_prediction/gene_interaction_prediction/data/{dataset_name}/predict'\n",
    "if model_type == 'Gears':\n",
    "    if use_pred_single:\n",
    "        raise ValueError('Gears model does not have predicted single perturbation')\n",
    "    else:\n",
    "        data_path = f'{parent_dir}/use_gt_single/num_gene_{num_gene}/Gears/seed_{random_seed}'\n",
    "elif model_type == 'morph':\n",
    "    if use_pred_single:\n",
    "        data_path = f'{parent_dir}/use_pred_single/{representation_type}_{model_type}/epochs_{num_epochs}_seed_{random_seed}'\n",
    "    else:\n",
    "        data_path = f'{parent_dir}/use_gt_single/num_gene_{num_gene}/{representation_type}_{model_type}/recon_loss_{recon_loss}/null_label_{null_label}/epochs_{num_epochs}/tolerance_epochs_{tolerance_epochs}/mxAlpha_{mxAlpha}/seed_{random_seed}/{model_name}'\n",
    "elif model_type == 'Control':\n",
    "    data_path = f'{parent_dir}/use_gt_single/num_gene_{num_gene}/Control/seed_{random_seed}'\n",
    "elif model_type == 'Truth':\n",
    "    data_path = f'{parent_dir}/use_gt_single/num_gene_{num_gene}/Truth'\n",
    "\n",
    "if n_subsamples is not None:\n",
    "    if filter_zeros:\n",
    "        model_fit_results_path = f'{data_path}/theilsen_results_n_subsamples_{n_subsamples}_filtered.pkl'\n",
    "    else:\n",
    "        model_fit_results_path = f'{data_path}/theilsen_results_n_subsamples_{n_subsamples}.pkl'\n",
    "    with open(model_fit_results_path, 'rb') as f:\n",
    "        model_fit_results = pickle.load(f)\n",
    "\n",
    "print('Loaded model fit results from', model_fit_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_results[model_fit_results['combination'] == 'MAPK1+PRTG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_results[model_fit_results['combination'] == 'FOXL2+HOXB9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate GI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from: https://gist.github.com/satra/aa3d19a12b74e9ab7941\n",
    "def distcorr(X, Y):\n",
    "    \"\"\" Compute the distance correlation function\n",
    "    \n",
    "    >>> a = [1,2,3,4,5]\n",
    "    >>> b = np.array([1,2,9,4,4])\n",
    "    >>> distcorr(a, b)\n",
    "    0.762676242417\n",
    "    \"\"\"\n",
    "    X = np.atleast_1d(X)\n",
    "    Y = np.atleast_1d(Y)\n",
    "    if np.prod(X.shape) == len(X):\n",
    "        X = X[:, None]\n",
    "    if np.prod(Y.shape) == len(Y):\n",
    "        Y = Y[:, None]\n",
    "    X = np.atleast_2d(X)\n",
    "    Y = np.atleast_2d(Y)\n",
    "    n = X.shape[0]\n",
    "    if Y.shape[0] != X.shape[0]:\n",
    "        raise ValueError('Number of samples must match')\n",
    "    a = squareform(pdist(X))\n",
    "    b = squareform(pdist(Y))\n",
    "    A = a - a.mean(axis=0)[None, :] - a.mean(axis=1)[:, None] + a.mean()\n",
    "    B = b - b.mean(axis=0)[None, :] - b.mean(axis=1)[:, None] + b.mean()\n",
    "    \n",
    "    dcov2_xy = (A * B).sum()/float(n * n)\n",
    "    dcov2_xx = (A * A).sum()/float(n * n)\n",
    "    dcov2_yy = (B * B).sum()/float(n * n)\n",
    "    dcor = np.sqrt(dcov2_xy)/np.sqrt(np.sqrt(dcov2_xx) * np.sqrt(dcov2_yy))\n",
    "    return dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_fit_results.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the required columns\n",
    "df['model_fit'] = df.apply(lambda row: distcorr(row['g_ab'], row['combined_effect']), axis=1)\n",
    "print('Finished model_fit')\n",
    "df['magnitude'] = np.sqrt(df['c_a']**2 + df['c_b']**2)\n",
    "print('Finished magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick chekcs\n",
    "row_temp = df.iloc[0]\n",
    "model_fit = distcorr(row_temp['g_ab'], row_temp['combined_effect'])\n",
    "assert row_temp['model_fit'] == model_fit\n",
    "magnitude = np.sqrt(row_temp['c_a']**2 + row_temp['c_b']**2)\n",
    "assert row_temp['magnitude'] == magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity'] = df.apply(lambda row: distcorr(np.stack([row['g_a'], row['g_b']], axis=1), row['g_ab']), axis=1)\n",
    "print('Finished similarity')\n",
    "\n",
    "# Calculate equality of contribution\n",
    "def equality_of_contribution(row):\n",
    "    dcor_a = distcorr(row['g_a'], row['g_ab'])\n",
    "    dcor_b = distcorr(row['g_b'], row['g_ab'])\n",
    "    min_dcor = min(dcor_a, dcor_b)\n",
    "    max_dcor = max(dcor_a, dcor_b)\n",
    "    return min_dcor / max_dcor\n",
    "\n",
    "df['equality_of_contribution'] = df.apply(equality_of_contribution, axis=1)\n",
    "print('Finished equality_of_contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick checks\n",
    "row_temp = df.iloc[10]\n",
    "dcor_a = distcorr(row_temp['g_a'], row_temp['g_ab'])\n",
    "dcor_b = distcorr(row_temp['g_b'], row_temp['g_ab'])\n",
    "min_dcor = min(dcor_a, dcor_b)\n",
    "max_dcor = max(dcor_a, dcor_b)\n",
    "equality_of_contribution = min_dcor / max_dcor\n",
    "assert row_temp['equality_of_contribution'] == equality_of_contribution\n",
    "\n",
    "similarity = distcorr(np.stack([row_temp['g_a'], row_temp['g_b']], axis=1), row_temp['g_ab'])\n",
    "assert row_temp['similarity'] == similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate dominance: |log_10(c_a/c_b)|\n",
    "df['dominance'] = np.abs(np.log10(np.abs(df['c_a'])/np.abs(df['c_b'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save gi scores into pickle file\n",
    "if n_subsamples is not None:\n",
    "    if filter_zeros:\n",
    "        with open(f'{data_path}/gi_scores_n_subsamples_{n_subsamples}_filtered.pkl', 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "        print(f'Saved gi scores into {data_path}/gi_scores_n_subsamples_{n_subsamples}_filtered.pkl')\n",
    "    else:\n",
    "        with open(f'{data_path}/gi_scores_n_subsamples_{n_subsamples}.pkl', 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "        print(f'Saved gi scores into {data_path}/gi_scores_n_subsamples_{n_subsamples}.pkl')\n",
    "else:\n",
    "    with open(f'{data_path}/gi_scores.pkl', 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "    print(f'Saved gi scores into {data_path}/gi_scores.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
